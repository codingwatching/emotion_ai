# Aura Backend Configuration
# ==========================

# Google API Configuration
GOOGLE_API_KEY=your-google-api-key-here

# Database Configuration
CHROMA_PERSIST_DIRECTORY=./aura_chroma_db
AURA_DATA_DIRECTORY=./aura_data

# Server Configuration
HOST=0.0.0.0
PORT=8000
DEBUG=false

# Logging Configuration
LOG_LEVEL=DEBUG

# MCP Server Configuration
MCP_SERVER_NAME=aura-companion
MCP_SERVER_VERSION=1.0.0

# Security Configuration
CORS_ORIGINS=["http://localhost:5173", "http://localhost:3000"]
VITE_API_URL=http://localhost:8000

# Features Configuration
ENABLE_EMOTIONAL_ANALYSIS=true
ENABLE_COGNITIVE_TRACKING=true
ENABLE_VECTOR_SEARCH=true
ENABLE_FILE_EXPORTS=true

# AI Response Configuration
# gemini-2.5-flash-preview-05-20
AURA_MODEL=gemini-2.5-flash
AURA_MAX_OUTPUT_TOKENS=1000000


# Thinking Configuration
THINKING_BUDGET=-1 # Token budget for AI reasoning- Dynamic Thinking =-1 Standard(1024-24576, max is 24576 for 2.5 flash)
INCLUDE_THINKING_IN_RESPONSE=false # Keep thinking separate from main response (displayed in AI Reasoning dropdown)
FORCE_PURE_THINKING_EXTRACTION=false # Force pure thinking extraction for debugging
THINKING_DEBUG=true # Enable detailed thinking debug logging

# Function Calling Configuration
MAX_FUNCTION_CALL_ROUNDS=3 # Maximum iterative function call rounds (thinking + response phases)
AFC_MAX_REMOTE_CALLS=10 # Maximum remote calls for main model (default for free tier)
AFC_AUTONOMIC_MAX_REMOTE_CALLS=30 # Maximum remote calls for autonomic model
# Autonomic System Configuration
# gemini-2.0-flash-lite
AURA_AUTONOMIC_MODEL=gemini-2.0-flash-lite
AURA_AUTONOMIC_MAX_OUTPUT_TOKENS=100000
AUTONOMIC_ENABLED=true
AUTONOMIC_TASK_THRESHOLD=medium  # low, medium, high- this is unclear and possibly not functional
# Analyze every Nth conversation to avoid interference (higher = less frequent)
AUTONOMIC_ANALYSIS_FREQUENCY=1  # This was added without my request and is probably really bad AI conception of "efficiency" hamstringing the systems! The autonomic analysis should be always on!!!


# Image Generation- not yet implemented
# gemini-2.0-flash-preview-image-generation


# Rate Limiting Configuration
AUTONOMIC_MAX_CONCURRENT_TASKS=30  # Optimal concurrency for 30 rpm limit
AUTONOMIC_RATE_LIMIT_RPM=30        # Requests per minute (safety margin below 30)
AUTONOMIC_RATE_LIMIT_RPD=1400      # Requests per day (safety margin below 1400)
AUTONOMIC_TIMEOUT_SECONDS=600       # Increased for higher concurrency

# Main Model Rate Limiting (user-configurable based on plan)
MAIN_MODEL_RATE_LIMIT_RPM=10       # Conservative default, increase based on user plan
MAIN_MODEL_RATE_LIMIT_RPD=500     # Daily limit for main model

# Queue Management
AUTONOMIC_QUEUE_MAX_SIZE=30       # Maximum queued tasks
AUTONOMIC_QUEUE_PRIORITY_ENABLED=true  # Enable priority-based processing
